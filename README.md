# ESA Satellite Telemetry Anomaly Detection

A machine learning pipeline for detecting anomalies in satellite telemetry data using the official ESA Anomaly Dataset. This system combines a GRU-based AutoEncoder with attention mechanisms and Random Forest classification to achieve industry-standard performance for mission-critical satellite operations.

![Python](https://img.shields.io/badge/python-v3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-v1.12+-red.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

## ğŸš€ Key Features

- **Attention-based feature extraction** from 87 telemetry channels
- **Multi-tier alerting system** (LOW/MEDIUM/HIGH sensitivity modes)
- **Comprehensive evaluation** with satellite-operations-specific metrics

## ğŸ“Š Performance

| Metric | Low Mode | Medium Mode | High Mode |
|--------|----------|-------------|-----------|
| **Precision** | 34.5% | 47.0% | 65.5% |
| **Recall** | 98.8% | 91.2% | 64.7% |
| **False Alarm Rate** | 62% | 34% | 11% |

*Tested on 170 real satellite anomalies from ESA Mission1 data*

## ğŸ›°ï¸ Architecture

### Two-Stage Pipeline
1. **AutoEncoder Stage**: GRU + Attention mechanism learns normal telemetry patterns
2. **Classification Stage**: Random Forest uses extracted features for final anomaly detection

### Feature Engineering
- **MSE Features**: Reconstruction errors per channel + total MSE
- **Latent Features**: 32-dimensional compressed representation
- **Attention Features**: Temporal attention weights and statistics
- **Total**: 56 engineered features from 87 raw telemetry channels

## ğŸ“ Project Structure

```
ESA-Anomaly-Analysis/
â”œâ”€â”€ attention_gru_autoencoder.py    # AutoEncoder architecture with attention
â”œâ”€â”€ training_gru_attn.py            # Stage 1: Train AutoEncoder on normal data
â”œâ”€â”€ export_attn_features.py         # Feature extraction pipeline
â”œâ”€â”€ train_rf_on_latent.py          # Stage 2: Train Random Forest classifier
â”œâ”€â”€ test_rf_downstream.py          # Comprehensive evaluation
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                     # This file
```

## ğŸ”§ Installation

### Prerequisites
- Python 3.8+
- CUDA-capable GPU (recommended)
- 16GB+ RAM for full pipeline

### Setup
```bash
git clone https://github.com/Gmvz3090/ESA-Anomaly-Analysis.git
cd ESA-Anomaly-Analysis

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Data Download
Download the ESA Anomaly Dataset:
- **Source**: [ESA Anomaly Dataset (Zenodo)](https://zenodo.org/records/12528696)
- **Files needed**: `3_months.train.csv` and `3_months.test.csv`
- **Alternative**: [MediaFire Link](https://www.mediafire.com/file/t98hqv8nir414pe/DataRar.rar/file)

Place both CSV files in the project root directory.

## ğŸš€ Quick Start

### Full Pipeline
```bash
# 1. Train AutoEncoder (learns normal patterns)
python training_gru_attn.py

# 2. Extract features from test data
python export_attn_features.py

# 3. Train Random Forest classifier
python train_rf_on_latent.py

# 4. Evaluate and generate report
python test_rf_downstream.py --mode {high/medium/low}
```


## ğŸ“ˆ Model Details

### AutoEncoder Architecture
- **Encoder**: GRU with attention mechanism for temporal feature extraction
- **Latent Space**: 32-dimensional compressed representation
- **Decoder**: Reconstructive GRU with teacher forcing during training
- **Training**: Unsupervised learning on 184,391 normal telemetry sequences

### Random Forest Classifier
- **Input Features**: 56 engineered features (MSE + latent + attention)
- **Training**: Supervised learning with class balancing for imbalanced data
- **Hyperparameters**: 200 trees, max depth 10, balanced class weights

### Data Processing
- **Window Size**: 10 timesteps (5 minutes of telemetry history)
- **Channels**: 87 satellite telemetry parameters
- **Preprocessing**: RobustScaler normalization, temporal sequence preservation
- **Split Strategy**: Stratified sampling ensuring anomalies in test set


## ğŸ“Š Evaluation Metrics

### Standard ML Metrics
- **Precision**: Percentage of alerts that are real anomalies
- **Recall**: Percentage of real anomalies detected
- **F1-Score**: Harmonic mean of precision and recall
- **AUC-ROC**: Area under receiver operating characteristic curve

### Satellite Operations Metrics
- **False Alarm Rate**: Percentage of monitoring time with false alerts
- **Detection Latency**: Time from anomaly occurrence to detection
- **Mission Phase Awareness**: Performance across different operational phases
- **Alert Fatigue Prevention**: Manageable alert volumes for operators

## ğŸ”¬ Technical Improvements

- âœ… **34-66% precision** (manageable false alarm rate)
- âœ… **91-99% recall** (high anomaly detection rate)
- âœ… **Configurable sensitivity** (operational flexibility)
- âœ… **Feature-rich detection** (56 features)

## ğŸ“š Dataset Information

### ESA Anomaly Dataset
- **Source**: First large-scale public satellite telemetry anomaly dataset
- **Missions**: Real data from 3 ESA satellite missions
- **Size**: ~31GB of telemetry data with expert annotations
- **Anomalies**: 852 labeled anomalies in Mission1 test data
- **Channels**: 87 telemetry parameters per timestep
- **Annotation**: Manual labeling by spacecraft operations engineers

### Data Characteristics
- **Imbalanced Classes**: 0.33% anomalies, 99.67% normal operations
- **Temporal Structure**: Sequential telemetry with 30-second intervals
- **Real-world Complexity**: Includes sensor noise, mission phase variations, environmental effects
- **Operational Relevance**: Reflects actual satellite monitoring scenarios

## ğŸ› ï¸ Development

### Running Tests
```bash
# Test AutoEncoder training
python training_gru_attn.py

# Test feature extraction
python export_attn_features.py

# Test Random Forest training
python train_rf_on_latent.py

# Comprehensive evaluation
python test_rf_downstream.py

```

### Model Artifacts
After training, the following artifacts are generated:
- `models/gru_attn_best.pt`: Trained AutoEncoder weights
- `models/rs_scaler.pkl`: Data preprocessing scaler
- `models/rf_downstream.pkl`: Trained Random Forest classifier
- `models/rf_features.txt`: Feature names for consistency
- `attn_features.csv`: Extracted features dataset

## ğŸ“– Research & Citations

If you use this work in your research, please cite:

```bibtex
@article{kotowski_european_2024,
title = {European {Space} {Agency} {Benchmark} for {Anomaly} {Detection} in {Satellite} {Telemetry}},
author = {Kotowski, Krzysztof and Haskamp, Christoph and Andrzejewski, Jacek and Ruszczak, Bogdan and Nalepa, Jakub and Lakey, Daniel and Collins, Peter and Kolmas, Aybike and Bartesaghi, Mauro and Martinez-Heras, Jose and De Canio, Gabriele},
date = {2024},
publisher = {arXiv},
doi = {10.48550/arXiv.2406.17826}
}
```

### References

De Canio, G. et al. (2023) Development of an actionable AI roadmap for automating mission operations. In, 2023 SpaceOps Conference. American Institute of Aeronautics and Astronautics, Dubai, United Arab Emirates. 

K. Kotowski K, C. Haskamp, J. Andrzejewski, B. Ruszczak, J. Nalepa, D. Lakey, P. Collins, A. Kolmas, M. Bartesaghi, J. Martinez-Heras, G. De Canio (2024) European Space Agency Benchmark for Anomaly Detection in Satellite Telemetry. arXiv:2406.17826.

## ğŸ¤ Contributing

Contributions are welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **ESA (European Space Agency)** for providing the first public satellite anomaly dataset

**Built for mission-critical satellite operations â€¢ Tested on real ESA data**
