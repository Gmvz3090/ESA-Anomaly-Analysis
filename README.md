# ðŸš€ ESA-Anomaly-Analysis

An advanced anomaly detection pipeline for multivariate satellite telemetry, using a GRU-based autoencoder with attention and a downstream Random Forest classifier.

---

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python)](https://www.python.org/)
[![Platform](https://img.shields.io/badge/Platform-Linux%20%7C%20Windows-informational)]()
[![Model](https://img.shields.io/badge/Model-GRU%20%2B%20Attention-green)]()
[![Status](https://img.shields.io/badge/Status-Trained%20%26%20Ready-brightgreen)]()

---

## ðŸ“¦ Overview

This project provides a complete and ready-to-use anomaly detection solution for ESA-like satellite telemetry data. It combines:

- GRU + Attention Autoencoder
- MSE-based anomaly filtering
- Random Forest trained on latent representations
- Window-based anomaly reporting with high recall and 0% false positives

---

## ðŸ§  Whatâ€™s Inside

- âœ… Ready-trained model (80% recall, 0% false positives)
- âœ… Easy retraining on your own data
- âœ… Windowed anomaly reports in `report.csv`

---

## ðŸ“ Folder Structure

```
ESA-Anomaly-Analysis/
â”œâ”€â”€ 3_months.train.csv         # Training data (from MediaFire)
â”œâ”€â”€ 3_months.test.csv          # Testing data (from MediaFire)
â”œâ”€â”€ attention_gru_autoencoder.py
â”œâ”€â”€ training_gru_attn.py
â”œâ”€â”€ export_attn_features.py
â”œâ”€â”€ train_rf_on_latent.py
â”œâ”€â”€ test_rf_downstream.py
â”œâ”€â”€ models/
â”œâ”€â”€ run_pipeline.sh
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ðŸ“¥ Download Demo Dataset

Test and training data used in this project:

ðŸ”— https://www.mediafire.com/file/t98hqv8nir414pe/DataRar.rar/file

After downloading and extracting, make sure the following files are in the root directory:

- `3_months.train.csv`
- `3_months.test.csv`

---

## ðŸ”„ Full Pipeline Usage

```bash
# Step 1: Create virtual environment
python -m venv .venv
source .venv/bin/activate

# Step 2: Install requirements
pip install -r requirements.txt

# Step 3: Run the full pipeline
bash run_pipeline.sh
```

Or run each step manually:

```bash
python training_gru_attn.py
python export_attn_features.py
python train_rf_on_latent.py
python test_rf_downstream.py
```

---

## ðŸ“Š Output: `report.csv`

Anomalies are reported in sliding windows of 1000 samples:

```
range,status,indices
0-999,OK,
1000-1999,ANOMALY,1099,1123
2000-2999,OK,
```

---

## ðŸ“š Source Datasets

This project is based on:
- ðŸ“¡ [Zenodo: ESA Mission1](https://zenodo.org/records/12528696)
- ðŸ›  [ESA-ADB preprocessing repo](https://github.com/kplabs-pl/ESA-ADB)

---

## ðŸ‘¤ Author

Built by **PXRLO**  
Feel free to contribute, open issues, or suggest improvements.

---


---

## ðŸ—ï¸ Own Training (Pipeline)

If you'd like to train the model yourself from scratch using your own healthy telemetry data:

### ðŸ”§ Prepare training data:
- Format: `.csv` with numerical columns (`channel_1`, ..., `telecommand_*`)
- Make sure it contains **no anomalies** (or remove anomaly rows)

### ðŸ§ª Steps:

```bash
# Train the autoencoder model
python training_gru_attn.py

# Extract latent vectors + errors from test data
python export_attn_features.py

# Train Random Forest classifier on high-error samples
python train_rf_on_latent.py

# Generate report based on trained RF
python test_rf_downstream.py
```

You can also run:

```bash
bash run_pipeline.sh
```

This runs the full pipeline on the demo dataset.

---

## âš¡ Use This Model (Pretrained)

If you simply want to **use the pretrained model** to analyze new telemetry:

### ðŸ“ Prepare your `.csv` file:
- Format: same columns as `3_months.test.csv` (no `is_anomaly_*` needed)
- Example: `my_telemetry.csv`

### ðŸš€ Analyze:

1. Replace file path in `export_attn_features.py`:
   ```python
   TEST = "my_telemetry.csv"
   ```

2. Run feature extraction:
   ```bash
   python export_attn_features.py
   ```

3. Run detection with pretrained RandomForest:
   ```bash
   python test_rf_downstream.py
   ```

Check `report.csv` for window-based anomaly summary.

---

## ðŸ§  How the Model Works

This pipeline uses a hybrid approach:

### 1. GRU + Attention Autoencoder
- Learns to reconstruct time windows of telemetry (sliding sequences)
- Uses **GRU** to process sequences and **attention** to focus on the most relevant time steps
- Calculates **MSE** per sequence (and per channel)

### 2. MSE-Based Filtering
- Only samples with high total MSE (`>10`) are considered as *suspicious*

### 3. Downstream Random Forest
- Latent vectors (`z_0` to `z_31`) from encoder are used to train a Random Forest
- Classifies whether high-error sample is truly anomalous or not

### 4. Reporting
- All predictions are grouped into **1000-sample windows**
- Each window is flagged as:
  - `OK` (if no anomaly detected)
  - `ANOMALY` with exact row indices

This design:
- Reduces false positives dramatically (0%)
- Retains high recall (80%+)
- Enables real-world batch monitoring

---
